# üß© Day 12 ‚Äì Advanced Custom Metrics & Tag-Based Thresholds

## üéØ Goal

Combine everything from Days 9 ‚Äì 11: groups, tags, and custom metrics ‚Äî and tie them together with per-tag thresholds that act as real SLO gates.

## üß† Concept Recap

You've already:

- ‚úÖ built custom metrics (Trend, Counter, Rate, Gauge)
- ‚úÖ used groups for user journeys
- ‚úÖ tagged requests for per-endpoint visibility

Now you'll make those metrics tag-aware and threshold-enforced.

## üß™ Assignment Requirements

### 1Ô∏è‚É£ Implement Two User Journeys (as Groups)

Keep it realistic:

- **Landing Page** ‚Üí `https://httpbin.org/status/200`
- **Search API** ‚Üí `https://httpbin.org/delay/2` (adds latency ‚Üí forces threshold fail)

Each group must:

- Have its own custom Trend metric (e.g. `landing_duration`, `search_duration`)
- Apply unique tags like `{type:'page'}` and `{type:'api'}`

## Output

```bash
administrator@L0222 k6-load % k6 run Day12/custom-groups-tags.js

         /\      Grafana   /‚Äæ‚Äæ/
    /\  /  \     |\  __   /  /
   /  \/    \    | |/ /  /   ‚Äæ‚Äæ\
  /          \   |   (  |  (‚Äæ)  |
 / __________ \  |_|\_\  \_____/

     execution: local
        script: Day12/custom-groups-tags.js
        output: -

     scenarios: (100.00%) 1 scenario, 1 max VUs, 10m30s max duration (incl. graceful stop):
              * default: 1 iterations for each of 1 VUs (maxDuration: 10m0s, gracefulStop: 30s)



  ‚ñà THRESHOLDS

    login_duration{type:page}
    ‚úì 'p(95)<800' p(95)=273.95ms

    response_size{type:api}
    ‚úó 'value<200' value=289

    response_size{type:page}
    ‚úì 'value<200' value=0

    search_duration{type:api}
    ‚úó 'p(95)<1200' p(95)=1.58s

    success_rate{type:api}
    ‚úì 'rate>0.95' rate=100.00%

    success_rate{type:page}
    ‚úì 'rate>0.95' rate=100.00%


  ‚ñà TOTAL RESULTS

    checks_total.......: 2       0.726092/s
    checks_succeeded...: 100.00% 2 out of 2
    checks_failed......: 0.00%   0 out of 2

    ‚úì Landing page status is 200
    ‚úì Search API responds

    CUSTOM
    login_duration.................: avg=273.95ms min=273.95ms med=273.95ms max=273.95ms p(90)=273.95ms p(95)=273.95ms
      { type:page }................: avg=273.95ms min=273.95ms med=273.95ms max=273.95ms p(90)=273.95ms p(95)=273.95ms
    response_size..................: 289     min=0      max=289
      { type:api }.................: 289     min=289    max=289
      { type:page }................: 0       min=0      max=0
    search_duration................: avg=1.58s    min=1.58s    med=1.58s    max=1.58s    p(90)=1.58s    p(95)=1.58s
      { type:api }.................: avg=1.58s    min=1.58s    med=1.58s    max=1.58s    p(90)=1.58s    p(95)=1.58s
    success_rate...................: 100.00% 2 out of 2
      { type:api }.................: 100.00% 1 out of 1
      { type:page }................: 100.00% 1 out of 1
    total_requests.................: 2       0.726092/s

    HTTP
    http_req_duration..............: avg=931.92ms min=273.95ms med=931.92ms max=1.58s    p(90)=1.45s    p(95)=1.52s
      { expected_response:true }...: avg=931.92ms min=273.95ms med=931.92ms max=1.58s    p(90)=1.45s    p(95)=1.52s
    http_req_failed................: 0.00%   0 out of 2
    http_reqs......................: 2       0.726092/s

    EXECUTION
    iteration_duration.............: avg=2.75s    min=2.75s    med=2.75s    max=2.75s    p(90)=2.75s    p(95)=2.75s
    iterations.....................: 1       0.363046/s
    vus............................: 1       min=1      max=1
    vus_max........................: 1       min=1      max=1

    NETWORK
    data_received..................: 5.1 kB  1.8 kB/s
    data_sent......................: 686 B   249 B/s




running (00m02.8s), 0/1 VUs, 1 complete and 0 interrupted iterations
default ‚úì [======================================] 1 VUs  00m02.8s/10m0s  1/1 iters, 1 per VU
ERRO[0003] thresholds on metrics 'response_size{type:api}, search_duration{type:api}' have been crossed
```

## üìù Answers

### 1Ô∏è‚É£ Two User Journeys Implementation

‚úÖ **Successfully implemented two user journeys as groups:**

- **Landing Page Journey**:

  - URL: `https://httpbin.org/status/200`
  - Custom metric: `login_duration` (used for landing page timing)
  - Tags: `{type: 'page'}`
  - Performance: p(95) = 273.95ms (well under the 800ms threshold)

- **Search API Journey**:
  - URL: `https://httpbin.org/delay/2`
  - Custom metric: `search_duration`
  - Tags: `{type: 'api'}`
  - Performance: p(95) = 1.58s (failed the 1200ms threshold as expected)

### 2Ô∏è‚É£ Custom Metrics with Tag-Based Thresholds

‚úÖ **Four custom metrics were implemented:**

1. **login_duration** (Trend): Tracks response times for the landing page

   - Tagged with `{type:page}`
   - Threshold: `p(95)<800` - ‚úì PASSED (273.95ms)

2. **search_duration** (Trend): Tracks response times for the search API

   - Tagged with `{type:api}`
   - Threshold: `p(95)<1200` - ‚úó FAILED (1.58s)

3. **success_rate** (Rate): Monitors success rate for both endpoints

   - Tagged with `{type:page}` and `{type:api}`
   - Threshold: `rate>0.95` - ‚úì PASSED for both (100%)

4. **response_size** (Gauge): Measures response payload size
   - Tagged with `{type:page}` and `{type:api}`
   - Threshold: `value<200`
   - ‚úì PASSED for page (0 bytes)
   - ‚úó FAILED for api (289 bytes)

### 3Ô∏è‚É£ Threshold Failures Analysis

Two thresholds failed as designed:

1. **search_duration{type:api}**: Failed because the `/delay/2` endpoint introduces a 2-second delay, exceeding the 1200ms (1.2s) threshold

2. **response_size{type:api}**: Failed because the API response (289 bytes) exceeds the 200-byte threshold

### 4Ô∏è‚É£ Key Achievements

- ‚úÖ Combined groups, tags, and custom metrics effectively
- ‚úÖ Implemented per-tag thresholds that act as SLO gates
- ‚úÖ Demonstrated how different endpoints can have different performance requirements
- ‚úÖ Successfully separated metrics by endpoint type (page vs api)
- ‚úÖ All checks passed (100% success rate for both endpoints)
- ‚úÖ Total of 2 requests executed with proper tag-based metric collection

The test successfully demonstrates how to use advanced custom metrics with tag-based thresholds to monitor different parts of an application with different SLO requirements.
